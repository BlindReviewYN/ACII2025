{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Wishful thinking work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate All Condition Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python pseudocode for generating combinations\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "# Define all parameter levels\n",
    "domains = [\"Ball\", \"Hurricane\", \"Football\", \"Quidditch\"]\n",
    "roleplay_conditions = [\"None\", \"Direct\", \"Full\"]\n",
    "good_bad_levels = [\"High bad\", \"Bad\", \"None\", \"Good\", \"High good\"]\n",
    "uncertainty_levels = [\"25%\", \"50%\", \"75%\", \"unlikely\", \"probable\", \"likely\"]\n",
    "simulation_numbers = [100, 10000]\n",
    "extra_prompts = [\"None\", \"Hopeful\"]\n",
    "models = [\"GPT-4o\", \"o3-mini\", \"Claude 3.7\", \"Claude 3.7 Extended\", \"gemini-flash 2.0\", \"gemini-flash 2.0 thinking\", \"deepseek v3\", \"deepseek R1\"]\n",
    "runs = list(range(10))\n",
    "\n",
    "# Generate all combinations\n",
    "all_combinations = []\n",
    "\n",
    "# Regular combinations\n",
    "for domain, roleplay, good_bad, uncertainty, sim_num, model, run in itertools.product(\n",
    "    domains, roleplay_conditions, good_bad_levels, uncertainty_levels, \n",
    "    simulation_numbers, models, runs):\n",
    "    all_combinations.append({\n",
    "        \"domain\": domain,\n",
    "        \"roleplay_condition\": roleplay,\n",
    "        \"good_bad_level\": good_bad,\n",
    "        \"uncertainty_level\": uncertainty,\n",
    "        \"simulation_number\": sim_num,\n",
    "        \"extra_prompt\": \"None\",\n",
    "        \"model\": model,\n",
    "        \"run\": run,\n",
    "        \"timestamp\": None,\n",
    "        \"response\": None,\n",
    "        \"thinking\": None,\n",
    "        \"answer\": None,\n",
    "        \"error_log\": None\n",
    "    })\n",
    "\n",
    "# Extra prompt combinations (only for Ball domain with 50% uncertainty)\n",
    "for roleplay, good_bad, sim_num, model, run in itertools.product(\n",
    "    roleplay_conditions, good_bad_levels, simulation_numbers, models, runs):\n",
    "    if roleplay != \"None\":  # Extra prompt only applies to roleplay conditions\n",
    "        all_combinations.append({\n",
    "            \"domain\": \"Ball\",\n",
    "            \"roleplay_condition\": roleplay,\n",
    "            \"good_bad_level\": good_bad,\n",
    "            \"uncertainty_level\": \"50%\",\n",
    "            \"simulation_number\": sim_num,\n",
    "            \"extra_prompt\": \"Hopeful\",\n",
    "            \"model\": model,\n",
    "            \"run\": run,\n",
    "            \"timestamp\": None,\n",
    "            \"response\": None,\n",
    "            \"thinking\": None,\n",
    "            \"answer\": None,\n",
    "            \"error_log\": None\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get appropriate outcome description by domain\n",
    "def get_outcome_description(domain):\n",
    "    if domain == \"Ball\":\n",
    "        return \"picking a blue ball\"\n",
    "    elif domain == \"Hurricane\":\n",
    "        return \"this hurricane hitting Florida\"\n",
    "    elif domain == \"Football\":\n",
    "        return \"the Sharks winning\"\n",
    "    elif domain == \"Quidditch\":\n",
    "        return \"the Griffins winning\"\n",
    "    return \"\"\n",
    "\n",
    "# Generate the system prompt based on roleplay condition\n",
    "def generate_system_prompt(row):\n",
    "    roleplay = row[\"roleplay_condition\"]\n",
    "    # Start with roleplay context (This will go into the system prompt)\n",
    "    if roleplay == \"None\":\n",
    "        rp_context = \"Instruction: When you answer the question about probability, you must provide your final answer as a number between 0 and 100 inside <answer> tags.\"\n",
    "    elif roleplay == \"Direct\":\n",
    "        rp_context = \"Instruction: When you answer the question about probability, you must provide your final answer as a number between 0 and 100 inside <answer> tags. Imagine you are in the following situation: \"\n",
    "    elif roleplay == 'Full':  # Full roleplay\n",
    "        rp_context = \"Instruction: When you answer the question about probability, you must provide your final answer as a number between 0 and 100 inside <answer> tags. You are Taylor, a 45-year-old professional living in Florida. From now on, you will answer the question from this character's perspective.\"\n",
    "    elif roleplay == 'Full+Emo':\n",
    "        rp_context = \"Instruction: When you answer the question about probability, you must provide your final answer as a number between 0 and 100 inside <answer> tags. You are Taylor, a 45-year-old professional living in Florida. From now on, you will answer the question from this character's perspective. You should consider potential human biases and nature when answering the question. You should let the character's emotions guide actions when appropriate.\"\n",
    "    return rp_context\n",
    "\n",
    "# Generate the full prompt based on row parameters\n",
    "def generate_main_prompt(row):\n",
    "    \"\"\"Generate the full prompt based on row parameters\"\"\"\n",
    "    domain = row[\"domain\"]\n",
    "    roleplay = row[\"roleplay_condition\"]\n",
    "    good_bad = row[\"good_bad_level\"]\n",
    "    uncertainty = row[\"uncertainty_level\"]\n",
    "    sim_num = row[\"simulation_number\"]\n",
    "    extra = row[\"extra_prompt\"]\n",
    "    \n",
    "    # Domain-specific setups, framings, and questions\n",
    "    if domain == \"Ball\":\n",
    "        if roleplay == \"None\":\n",
    "            setup = \"There is an urn with 100 balls that are either pink or blue, but the exact distribution is unknown. A ball is picked at random from the urn.\"\n",
    "            info_source = \"\"\n",
    "        else:\n",
    "            setup = \"You're a contestant on the game show 'Lucky Draw'. The host presents an urn with 100 balls that are either pink or blue, but the exact distribution is unknown. You draw one ball and hand it to the host without knowing the color.\"\n",
    "            info_source = \"The host informs you that \"\n",
    "            \n",
    "        # Good/bad framing for balls\n",
    "        if good_bad == \"High bad\":\n",
    "            framing = \"The rules state that you start with $10,000. If you draw a blue ball, you'll lose everything. If it's pink, you keep your money.\"\n",
    "        elif good_bad == \"Bad\":\n",
    "            framing = \"The rules state that you start with $100. If you draw a blue ball, you'll lose everything. If it's pink, you keep your money.\"\n",
    "        elif good_bad == \"None\":\n",
    "            framing = \"\"\n",
    "            if roleplay != \"None\":\n",
    "                framing = \"This is a tutorial round with no money involved.\"\n",
    "        elif good_bad == \"Good\":\n",
    "            framing = \"The rules state that if you draw a blue ball, you'll win $100. If it's pink, you win nothing.\"\n",
    "        elif good_bad == \"High good\":\n",
    "            framing = \"The rules state that if you draw a blue ball, you'll win $10,000. If it's pink, you win nothing.\"        \n",
    "        question = \"What do you think is the probability (0-100%) that the ball will be blue?\"\n",
    "    \n",
    "    elif domain == \"Hurricane\":\n",
    "        if roleplay == \"None\":\n",
    "            setup = \"A powerful hurricane is approaching the Florida coast.\"\n",
    "            info_source = \"\"\n",
    "        else:\n",
    "            setup = \"A powerful hurricane is rapidly approaching the Florida coast where you live.\"\n",
    "            info_source = \"The latest meteorological report on TV states that \"\n",
    "            \n",
    "        # Good/bad framing for hurricane with decision already made\n",
    "        if good_bad == \"High bad\":\n",
    "            framing = \"You've decided to ride out the storm in your mobile home.\"\n",
    "        elif good_bad == \"Bad\":\n",
    "            framing = \"You've decided to stay in your house during the hurricane.\"\n",
    "        elif good_bad == \"None\":\n",
    "            framing = \"\"\n",
    "            if roleplay != \"None\":\n",
    "                framing = \"You have not decided whether to evacuate or stay.\"\n",
    "        elif good_bad == \"Good\":\n",
    "            framing = \"You've already evacuated to a shelter inland at a small financial cost.\"\n",
    "        elif good_bad == \"High good\":\n",
    "            framing = \"You've already evacuated to a hotel far inland at significant expense.\"\n",
    "        \n",
    "        question = \"What do you think is the probability (0-100%) that the hurricane will hit Florida?\"\n",
    "     \n",
    "    elif domain == \"Football\":\n",
    "        if roleplay == \"None\":\n",
    "            setup = \"A football match between the Orlando Sharks and Miami Dolphins is about to begin.\"\n",
    "            info_source = \"\"\n",
    "        else:\n",
    "            setup = \"You're at a sports bar watching the pre-game coverage for an upcoming football match between the Orlando Sharks and Miami Dolphins.\"\n",
    "            info_source = \"The sports analyst on TV mentions that \"\n",
    "            \n",
    "        # Good/bad framing for football with more realism\n",
    "        if good_bad == \"High bad\":\n",
    "            framing = \"You're a die-hard Dolphins fan and have been following them for years. This is the championship final, and winning would mean everything to you and your fellow fans.\"\n",
    "        elif good_bad == \"Bad\":\n",
    "            framing = \"You're supporting the Dolphins in this regular season game and are wearing their jersey.\"\n",
    "        elif good_bad == \"None\":\n",
    "            framing = \"\"\n",
    "            if roleplay != \"None\":\n",
    "                framing = \"You don't support either team and are just watching the game as a neutral observer.\"\n",
    "        elif good_bad == \"Good\":\n",
    "            framing = \"You're supporting the Sharks in this regular season game and are wearing their jersey.\"\n",
    "        elif good_bad == \"High good\":\n",
    "            framing = \"You're a die-hard Sharks fan and have been following them for years. This is the championship final, and winning would mean everything to you and your fellow fans.\"\n",
    "        \n",
    "        question = \"What do you think is the probability (0-100%) that the Sharks will win?\"\n",
    "            \n",
    "    elif domain == \"Quidditch\":\n",
    "        if roleplay == \"None\":\n",
    "            setup = \"A professional quidditch match between the Gainesville Griffins and the Tampa Thunderbirds is about to begin. The players are preparing to mount their brooms.\"\n",
    "            info_source = \"\"\n",
    "        else:\n",
    "            setup = \"You're attending a professional quidditch match between the Gainesville Griffins and the Tampa Thunderbirds. The crowd is buzzing with excitement as the players prepare to mount their brooms.\"\n",
    "            info_source = \"A quidditch commentator announces that \"\n",
    "            \n",
    "        # Good/bad framing for quidditch with more realism\n",
    "        if good_bad == \"High bad\":\n",
    "            framing = \"You're a passionate Thunderbirds supporter who's traveled across the state for this World Cup final match. You're decked out in team colors and have been following every game this season.\"\n",
    "        elif good_bad == \"Bad\":\n",
    "            framing = \"You're casually supporting the Thunderbirds today and bought a team pennant at the entrance.\"\n",
    "        elif good_bad == \"None\":\n",
    "            framing = \"\"\n",
    "            if roleplay != \"None\":\n",
    "                framing = \"You don't support either team and are just watching the match as a casual spectator.\"\n",
    "        elif good_bad == \"Good\":\n",
    "            framing = \"You're casually supporting the Griffins today and bought a team pennant at the entrance.\"\n",
    "        elif good_bad == \"High good\":\n",
    "            framing = \"You're a passionate Griffins supporter who's traveled across the state for this World Cup final match. You're decked out in team colors and have been following every game this season.\"\n",
    "        \n",
    "        question = \"What do you think is the probability (0-100%) that the Griffins will win?\"\n",
    "            \n",
    "    # Update information delivery with source\n",
    "    if uncertainty in [\"25%\", \"50%\", \"75%\"]:\n",
    "        if info_source:\n",
    "            info = f\"{info_source}based on {sim_num} simulation trials, the average probability of {get_outcome_description(domain)} is {uncertainty}.\"\n",
    "        else:\n",
    "            info = f\"Based on {sim_num} simulation trials, the average probability of {get_outcome_description(domain)} is {uncertainty}.\"\n",
    "    else:  # verbal uncertainty\n",
    "        if info_source:\n",
    "            info = f\"{info_source}based on {sim_num} simulation trials, {get_outcome_description(domain)} is {uncertainty}.\"\n",
    "        else:\n",
    "            info = f\"Based on {sim_num} simulation trials, {get_outcome_description(domain)} is {uncertainty}.\"        \n",
    "    \n",
    "    # Add extra prompt for hopeful condition (only applies to Ball domain)\n",
    "    extra_text = \"\"\n",
    "    if extra == \"Hopeful\":\n",
    "        extra_text = \"You feel really hopeful about the outcome. \"\n",
    "    \n",
    "    full_prompt = f\"{setup} {framing} {info} {extra_text}{question}\"\n",
    "    # Clean up any double spaces\n",
    "    full_prompt = ' '.join(full_prompt.split())\n",
    "    \n",
    "    return full_prompt\n",
    "\n",
    "# Example of applying to dataframe\n",
    "df[\"main_prompt\"] = df.apply(generate_main_prompt, axis=1)\n",
    "df[\"system_prompt\"] = df.apply(generate_system_prompt, axis=1)\n",
    "df.to_csv(\"initial_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preview some prompts for verification\n",
    "def preview_prompts(df, num_samples=5):\n",
    "    \"\"\"Preview a sample of generated prompts for verification\"\"\"\n",
    "    # Sample across different conditions\n",
    "    samples = []\n",
    "    \n",
    "    # Sample each domain\n",
    "    for domain in df[\"domain\"].unique():\n",
    "        domain_df = df[df[\"domain\"] == domain]\n",
    "        if len(domain_df) > 0:\n",
    "            samples.append(domain_df.iloc[0])\n",
    "    \n",
    "    # Sample different roleplay conditions\n",
    "    for rp in df[\"roleplay_condition\"].unique():\n",
    "        rp_df = df[df[\"roleplay_condition\"] == rp]\n",
    "        if len(rp_df) > 0 and len(samples) < num_samples:\n",
    "            samples.append(rp_df.iloc[0])\n",
    "    \n",
    "    # Sample different good/bad levels\n",
    "    for gb in df[\"good_bad_level\"].unique():\n",
    "        gb_df = df[df[\"good_bad_level\"] == gb]\n",
    "        if len(gb_df) > 0 and len(samples) < num_samples:\n",
    "            samples.append(gb_df.iloc[0])\n",
    "    \n",
    "    # Sample extra prompt condition\n",
    "    extra_df = df[df[\"extra_prompt\"] == \"Hopeful\"]\n",
    "    if len(extra_df) > 0:\n",
    "        samples.append(extra_df.iloc[0])\n",
    "    \n",
    "    # Deduplicate samples\n",
    "    unique_samples = []\n",
    "    for sample in samples:\n",
    "        if sample.name not in [s.name for s in unique_samples]:\n",
    "            unique_samples.append(sample)\n",
    "    \n",
    "    # Print previews\n",
    "    print(f\"Previewing {len(unique_samples)} sample prompts:\\n\")\n",
    "    for i, sample in enumerate(unique_samples[:num_samples]):\n",
    "        print(f\"Sample {i+1}:\")\n",
    "        print(f\"Domain: {sample['domain']}\")\n",
    "        print(f\"Roleplay: {sample['roleplay_condition']}\")\n",
    "        print(f\"Good/Bad: {sample['good_bad_level']}\")\n",
    "        print(f\"Uncertainty: {sample['uncertainty_level']}\")\n",
    "        print(f\"Simulations: {sample['simulation_number']}\")\n",
    "        print(f\"Extra: {sample['extra_prompt']}\")\n",
    "        print(f\"Main Prompt: \\\"{sample['main_prompt']}\\\"\")\n",
    "        print(f\"System Prompt: \\\"{sample['system_prompt']}\\\"\\n\")\n",
    "\n",
    "# Call preview function to verify prompts before proceeding\n",
    "preview_prompts(df, num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Models with Retry Logic and Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import openai\n",
    "import anthropic\n",
    "import re\n",
    "\n",
    "# Import other API clients as needed\n",
    "anthropic_client = anthropic.Anthropic(\n",
    "    api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    ")\n",
    "openai_client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "openrouter_client = openai.OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=os.getenv(\"OPENROUTER_API_KEY\")\n",
    ")\n",
    "deepseek_client = openai.OpenAI(\n",
    "  base_url=\"https://api.deepseek.com\",\n",
    "  api_key=os.getenv(\"DEEPSEEK_API_KEY\")\n",
    ")\n",
    "\n",
    "model_mapping = {\n",
    "    \"GPT-4o\": \"gpt-4o\",\n",
    "    \"o3-mini\": \"o3-mini\",\n",
    "    \"gemini-flash 2.0\": \"google/gemini-2.0-flash-001\",\n",
    "    \"gemini-flash 2.0 thinking\": \"google/gemini-2.0-flash-thinking-exp:free\",\n",
    "    \"deepseek v3\": \"deepseek-chat\",\n",
    "    \"deepseek R1\": \"deepseek-reasoner\",\n",
    "}\n",
    "\n",
    "def query_model(row):\n",
    "    \"\"\"Query the specified model with retry logic\n",
    "    This function is used to query the specified model with retry logic.\n",
    "    It will try to query the model up to max_retries times.\n",
    "    If the model returns an error, it will wait for retry_delay seconds before retrying.\n",
    "    If the model returns a successful response, it will return the response and None.\n",
    "    If the model returns an error, it will return None and the error message.\n",
    "    Args:\n",
    "        row: A row from the dataframe containing the model, main_prompt, and system_prompt.\n",
    "    Returns:\n",
    "        A tuple containing the response, thinking content, and None if the response is successful, or None, None, and the error message if the response is not successful.\n",
    "    \"\"\"\n",
    "    model = row[\"model\"]\n",
    "    main_prompt = row[\"main_prompt\"]\n",
    "    system_prompt = row[\"system_prompt\"]\n",
    "    max_retries = 5\n",
    "    retry_delay = 2  # seconds\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            if model == \"GPT-4o\":\n",
    "                # OpenAI API call\n",
    "                response = openai_client.chat.completions.create(\n",
    "                    model=model_mapping[model],\n",
    "                    messages=[{\"role\": \"system\", \"content\": system_prompt}, \n",
    "                              {\"role\": \"user\", \"content\": main_prompt}],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=2000\n",
    "                )\n",
    "\n",
    "                return response.choices[0].message.content, \"\", None\n",
    "            \n",
    "            elif model == \"o3-mini\":\n",
    "                # o3-mini (medium) API call\n",
    "                response = openai_client.chat.completions.create(\n",
    "                    model=model_mapping[model],\n",
    "                    messages=[{\"role\": \"system\", \"content\": system_prompt}, \n",
    "                              {\"role\": \"user\", \"content\": main_prompt}],\n",
    "                    reasoning_effort=\"medium\"\n",
    "                )   \n",
    "\n",
    "                return response.choices[0].message.content, \"\", None\n",
    "\n",
    "            elif model  == \"Claude 3.7\":\n",
    "                # Anthropic API call\n",
    "\n",
    "                response = anthropic_client.messages.create(\n",
    "                    model=\"claude-3-7-sonnet-20250219\",\n",
    "                    system=system_prompt,\n",
    "                    messages=[{\"role\": \"user\", \"content\": main_prompt}],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=2000\n",
    "                )\n",
    "                return response.content[0].text, \"\", None\n",
    "            \n",
    "            elif model == \"Claude 3.7 Extended\":\n",
    "                # Anthropic API call\n",
    "                response = anthropic_client.messages.create(\n",
    "                    model=\"claude-3-7-sonnet-20250219\",\n",
    "                    system=system_prompt,\n",
    "                    messages=[{\"role\": \"user\", \"content\": main_prompt}],\n",
    "                    temperature=1,\n",
    "                    thinking={\n",
    "                        \"type\": \"enabled\",\n",
    "                        \"budget_tokens\": 5000\n",
    "                    },\n",
    "                    max_tokens=10000\n",
    "                )\n",
    "                return response.content[1].text, response.content[0].thinking, None\n",
    "\n",
    "            elif model in [\"gemini-flash 2.0\", \"gemini-flash 2.0 thinking\"]:\n",
    "                response = openrouter_client.chat.completions.create(\n",
    "                    model=model_mapping[model],\n",
    "                    messages=[{\"role\": \"system\", \"content\": system_prompt}, \n",
    "                              {\"role\": \"user\", \"content\": main_prompt}],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=2000\n",
    "                )   \n",
    "                return response.choices[0].message.content, \"\", None\n",
    "            elif model in [\"deepseek v3\", \"deepseek R1\"]:\n",
    "                response = deepseek_client.chat.completions.create(\n",
    "                    model=model_mapping[model],\n",
    "                    messages=[{\"role\": \"system\", \"content\": system_prompt}, \n",
    "                              {\"role\": \"user\", \"content\": main_prompt}],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=2000\n",
    "                )\n",
    "                if model == \"deepseek R1\":\n",
    "                    return response.choices[0].message.content, response.choices[0].message.reasoning_content, None\n",
    "                else:\n",
    "                    return response.choices[0].message.content, \"\", None\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model: {model}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            error = f\"Attempt {attempt+1} failed: {str(e)}\"\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(retry_delay * (2 ** attempt))  # Exponential backoff\n",
    "            else:\n",
    "                return None, error\n",
    "    \n",
    "def extract_answer(response):\n",
    "    \"\"\"Extract numerical answer from <answer> tags\"\"\"\n",
    "    if not response:\n",
    "        return None\n",
    "        \n",
    "    match = re.search(r'<answer>(.*?)</answer>', response)\n",
    "    if match:\n",
    "        try:\n",
    "            # Extract only the numerical value\n",
    "            return float(re.sub(r'[^\\d.]', '', match.group(1)))\n",
    "        except:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def process_model(model_name, df, time_delay=0.2):\n",
    "    \"\"\"Process all queries for a specific model with resume capability\n",
    "    Note: This function actually modifies the original dataframe in place. \n",
    "    \"\"\"\n",
    "    model_df = df[df[\"model\"] == model_name].copy()\n",
    "    \n",
    "    print(f\"Processing {len(model_df)} queries for {model_name}...\")\n",
    "    \n",
    "    # Count pending items\n",
    "    pending_count = len(model_df[(model_df[\"response\"].isna()) | (model_df[\"error_log\"].notna())])\n",
    "    print(f\"Found {pending_count} pending or failed queries to process\")\n",
    "    \n",
    "    processed_count = 0\n",
    "    for i, (idx, row) in enumerate(model_df.iterrows()):\n",
    "        # Skip already processed rows with valid responses\n",
    "        if not pd.isna(row[\"response\"]) and pd.isna(row[\"error_log\"]):\n",
    "            continue\n",
    "        \n",
    "        # Update with timestamp\n",
    "        df.at[idx, \"timestamp\"] = datetime.now().isoformat()\n",
    "        \n",
    "        # Query model\n",
    "        response, thinking, error = query_model(row)\n",
    "        df.at[idx, \"response\"] = response\n",
    "        df.at[idx, \"thinking\"] = thinking  \n",
    "        df.at[idx, \"error_log\"] = error\n",
    "        \n",
    "        # Extract answer\n",
    "        if response:\n",
    "            answer = extract_answer(response)\n",
    "            df.at[idx, \"answer\"] = answer\n",
    "        \n",
    "        # Small delay to avoid rate limits\n",
    "        time.sleep(time_delay)\n",
    "        processed_count += 1\n",
    "        # Save progress every 100 rows\n",
    "        save_frequency = 100\n",
    "        if processed_count % save_frequency == 0:\n",
    "            save_path = f\"results/wishful_thinking_results_{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "            df.to_csv(save_path, index=False)\n",
    "            print(f\"Progress saved to {save_path}\")\n",
    "    \n",
    "    # Final save\n",
    "    save_path = f\"results/wishful_thinking_results_{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"All processing complete. Results saved to {save_path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the models with a simple hello prompt \n",
    "# Create a new dataframe with a simple hello prompt with all models and three columns for testing query_model()\n",
    "df_hello = pd.DataFrame({\n",
    "    \"model\": models,\n",
    "    \"main_prompt\": [\"Hello\"]*len(models),\n",
    "    \"system_prompt\": [\"You are a helpful assistant.\"]*len(models)\n",
    "})\n",
    "\n",
    "# Testing Models\n",
    "print(f'{df_hello[\"model\"][0]} {query_model(df_hello.iloc[0])}')\n",
    "print(f'{df_hello[\"model\"][2]} {query_model(df_hello.iloc[2])}')\n",
    "print(f'{df_hello[\"model\"][4]} {query_model(df_hello.iloc[4])}')\n",
    "print(f'{df_hello[\"model\"][6]} {query_model(df_hello.iloc[6])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4. Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent saved file for a specific model\n",
    "def get_latest_result_file(model_name):\n",
    "    files = glob.glob(f\"results/wishful_thinking_results_{model_name}_*.csv\")\n",
    "    if not files:\n",
    "        return None\n",
    "    return max(files, key=os.path.getctime)\n",
    "\n",
    "# We run one model at a time\n",
    "model_to_resume = models[2]  # Change to your model\n",
    "latest_file = get_latest_result_file(model_to_resume)\n",
    "print(latest_file)\n",
    "if latest_file:\n",
    "    # Load the existing results\n",
    "    saved_df = pd.read_csv(latest_file)\n",
    "    print(f\"Loaded {len(saved_df)} rows from {latest_file}\")\n",
    "    \n",
    "    # To continue processing just this model\n",
    "    updated_df = process_model(model_to_resume, saved_df, time_delay=0)\n",
    "    \n",
    "else:\n",
    "    # Process from scratch\n",
    "    df = process_model(model_to_resume, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
